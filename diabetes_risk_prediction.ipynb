{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmDvQLGPmKtM",
        "outputId": "238b633b-a6b9-49f4-c671-77b2ef255992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Downloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.28.9 xgboost-3.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0qzLm83rAxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8_sIDlOkTs1",
        "outputId": "e077ecf7-b65e-4c59-98f3-04fe43d402f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Loading data...\n",
            "Test set loaded with 300000 rows. Preparing for submission...\n",
            "Training on 700000 rows, Predicting on 300000 rows...\n",
            "[0]\tvalidation_0-auc:0.64289\n",
            "[100]\tvalidation_0-auc:0.71892\n",
            "[200]\tvalidation_0-auc:0.72311\n",
            "[300]\tvalidation_0-auc:0.72449\n",
            "[400]\tvalidation_0-auc:0.72532\n",
            "[500]\tvalidation_0-auc:0.72562\n",
            "[600]\tvalidation_0-auc:0.72585\n",
            "[700]\tvalidation_0-auc:0.72583\n",
            "[717]\tvalidation_0-auc:0.72589\n",
            "Fold 1 complete.\n",
            "[0]\tvalidation_0-auc:0.64204\n",
            "[100]\tvalidation_0-auc:0.71661\n",
            "[200]\tvalidation_0-auc:0.72077\n",
            "[300]\tvalidation_0-auc:0.72217\n",
            "[400]\tvalidation_0-auc:0.72326\n",
            "[500]\tvalidation_0-auc:0.72378\n",
            "[600]\tvalidation_0-auc:0.72431\n",
            "[700]\tvalidation_0-auc:0.72447\n",
            "[800]\tvalidation_0-auc:0.72458\n",
            "[900]\tvalidation_0-auc:0.72463\n",
            "[994]\tvalidation_0-auc:0.72452\n",
            "Fold 2 complete.\n",
            "[0]\tvalidation_0-auc:0.64168\n",
            "[100]\tvalidation_0-auc:0.71737\n",
            "[200]\tvalidation_0-auc:0.72147\n",
            "[300]\tvalidation_0-auc:0.72293\n",
            "[400]\tvalidation_0-auc:0.72394\n",
            "[500]\tvalidation_0-auc:0.72452\n",
            "[600]\tvalidation_0-auc:0.72484\n",
            "[700]\tvalidation_0-auc:0.72522\n",
            "[800]\tvalidation_0-auc:0.72522\n",
            "[850]\tvalidation_0-auc:0.72522\n",
            "Fold 3 complete.\n",
            "[0]\tvalidation_0-auc:0.64723\n",
            "[100]\tvalidation_0-auc:0.71859\n",
            "[200]\tvalidation_0-auc:0.72319\n",
            "[300]\tvalidation_0-auc:0.72473\n",
            "[400]\tvalidation_0-auc:0.72565\n",
            "[500]\tvalidation_0-auc:0.72593\n",
            "[600]\tvalidation_0-auc:0.72615\n",
            "[700]\tvalidation_0-auc:0.72623\n",
            "[748]\tvalidation_0-auc:0.72628\n",
            "Fold 4 complete.\n",
            "[0]\tvalidation_0-auc:0.64657\n",
            "[100]\tvalidation_0-auc:0.71810\n",
            "[200]\tvalidation_0-auc:0.72238\n",
            "[300]\tvalidation_0-auc:0.72353\n",
            "[400]\tvalidation_0-auc:0.72446\n",
            "[500]\tvalidation_0-auc:0.72508\n",
            "[600]\tvalidation_0-auc:0.72531\n",
            "[700]\tvalidation_0-auc:0.72554\n",
            "[800]\tvalidation_0-auc:0.72554\n",
            "[847]\tvalidation_0-auc:0.72552\n",
            "Fold 5 complete.\n",
            "Final submission row count: 300000\n",
            "File 'submission_final.csv' is ready!\n"
          ]
        }
      ],
      "source": [
        "# 0. Install missing library immediately\n",
        "!pip install --upgrade xgboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Load Data\n",
        "print(\"Loading data...\")\n",
        "# We use dropna on train only; the test set must remain at 300,000 rows\n",
        "train = pd.read_csv('train.csv').dropna(subset=['diagnosed_diabetes'])\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"Test set loaded with {len(test)} rows. Preparing for submission...\")\n",
        "\n",
        "# Convert target to integer\n",
        "train['diagnosed_diabetes'] = train['diagnosed_diabetes'].astype(int)\n",
        "\n",
        "# 2. Advanced Feature Engineering\n",
        "def apply_fe(df):\n",
        "    # Use float32 to save memory on large datasets\n",
        "    df['tg_hdl_ratio'] = (df['triglycerides'] / (df['hdl_cholesterol'] + 1e-6)).astype('float32')\n",
        "    df['remnant_cholesterol'] = (df['cholesterol_total'] - (df['hdl_cholesterol'] + df['ldl_cholesterol'])).astype('float32')\n",
        "    df['pulse_pressure'] = (df['systolic_bp'] - df['diastolic_bp']).astype('float32')\n",
        "    df['bmi_age'] = (df['bmi'] * df['age']).astype('float32')\n",
        "\n",
        "    risk_factors = ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
        "    df['total_comorbidities'] = df[risk_factors].sum(axis=1).astype('int32')\n",
        "    return df\n",
        "\n",
        "train = apply_fe(train)\n",
        "test = apply_fe(test)\n",
        "\n",
        "# 3. Handle Categorical Columns\n",
        "cat_cols = train.select_dtypes(include=['object']).columns\n",
        "for col in cat_cols:\n",
        "    # Frequency encoding\n",
        "    freq = train[col].value_counts(normalize=True)\n",
        "    train[col + '_freq'] = train[col].map(freq).fillna(0).astype('float32')\n",
        "    test[col + '_freq'] = test[col].map(freq).fillna(0).astype('float32')\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([train[col], test[col]]).astype(str)\n",
        "    le.fit(combined)\n",
        "    train[col] = le.transform(train[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "\n",
        "# 4. Final Data Prep\n",
        "# Ensure X_test has all 300,000 rows\n",
        "X = train.drop(columns=['id', 'diagnosed_diabetes'])\n",
        "y = train['diagnosed_diabetes']\n",
        "X_test = test.drop(columns=['id'])\n",
        "test_ids = test['id']\n",
        "\n",
        "# 5. Competition-Grade Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "test_preds = np.zeros(len(X_test)) # This will hold 300,000 predictions\n",
        "oof_preds = np.zeros(len(X))\n",
        "\n",
        "print(f\"Training on {len(X)} rows, Predicting on {len(X_test)} rows...\")\n",
        "\n",
        "for fold, (t_idx, v_idx) in enumerate(skf.split(X, y)):\n",
        "    xt, xv = X.iloc[t_idx], X.iloc[v_idx]\n",
        "    yt, yv = y.iloc[t_idx], y.iloc[v_idx]\n",
        "\n",
        "    y = y.fillna(0).astype(int)\n",
        "    model = xgb.XGBClassifier(\n",
        "        tree_method='hist',      # Much faster for large datasets\n",
        "        n_estimators=1000,       # Reduced slightly for speed, but boosted by learning rate\n",
        "        learning_rate=0.05,\n",
        "        max_depth=7,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.6,\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='auc',\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        early_stopping_rounds =100\n",
        "    )\n",
        "\n",
        "    # Using the standard fit (early_stopping_rounds inside fit)\n",
        "    model.fit(xt, yt, eval_set=[(xv, yv)], verbose=100)\n",
        "\n",
        "    # Accumulate predictions\n",
        "    oof_preds[v_idx] = model.predict_proba(xv)[:, 1]\n",
        "    test_preds += model.predict_proba(X_test)[:, 1] / 5\n",
        "    print(f\"Fold {fold+1} complete.\")\n",
        "\n",
        "# 6. Final Submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'diagnosed_diabetes': test_preds\n",
        "})\n",
        "\n",
        "# Final check:\n",
        "print(f\"Final submission row count: {len(submission)}\")\n",
        "submission.to_csv('submission_final.csv', index=False)\n",
        "print(\"File 'submission_final.csv' is ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dia07jOHrMWr",
        "outputId": "eea31c48-4951-46e6-fd4c-d9be9bd6fa55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "üöÄ Starting Blending: Model 1 (XGBoost) + Model 2 (HistGBM)...\n",
            "‚úÖ Fold 1 complete.\n",
            "‚úÖ Fold 2 complete.\n",
            "‚úÖ Fold 3 complete.\n",
            "‚úÖ Fold 4 complete.\n",
            "‚úÖ Fold 5 complete.\n",
            "Success! Exporting 300000 rows.\n"
          ]
        }
      ],
      "source": [
        "# 1. Fix the environment errors first\n",
        "!pip install --upgrade xgboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "train = pd.read_csv('train.csv').dropna(subset=['diagnosed_diabetes'])\n",
        "test = pd.read_csv('test.csv')\n",
        "train['diagnosed_diabetes'] = train['diagnosed_diabetes'].astype(int)\n",
        "\n",
        "# --- 2. Advanced Feature Engineering (The Signal) ---\n",
        "def advanced_fe(df):\n",
        "    # Metabolic & Arterial signals\n",
        "    df['age_bmi'] = (df['age'] * df['bmi']).astype('float32')\n",
        "    df['non_hdl'] = (df['cholesterol_total'] - df['hdl_cholesterol']).astype('float32')\n",
        "    df['aip'] = np.log10(df['triglycerides'] / (df['hdl_cholesterol'] + 1e-6)).astype('float32')\n",
        "    df['map'] = ((df['systolic_bp'] + 2 * df['diastolic_bp']) / 3).astype('float32')\n",
        "\n",
        "    # Ratios\n",
        "    df['bmi_wthr'] = (df['bmi'] * df['waist_to_hip_ratio']).astype('float32')\n",
        "    return df\n",
        "\n",
        "train = advanced_fe(train)\n",
        "test = advanced_fe(test)\n",
        "\n",
        "# --- 3. Encoding ---\n",
        "cat_cols = train.select_dtypes(include=['object']).columns\n",
        "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train[cat_cols] = oe.fit_transform(train[cat_cols].astype(str))\n",
        "test[cat_cols] = oe.transform(test[cat_cols].astype(str))\n",
        "\n",
        "X = train.drop(columns=['id', 'diagnosed_diabetes'])\n",
        "y = train['diagnosed_diabetes']\n",
        "X_test = test.drop(columns=['id'])\n",
        "\n",
        "# --- 4. The Blending Strategy ---\n",
        "# We will use 5 folds and 2 different models\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "final_preds = np.zeros(len(X_test)) # Target: 300,000 rows\n",
        "\n",
        "print(\"üöÄ Starting Blending: Model 1 (XGBoost) + Model 2 (HistGBM)...\")\n",
        "\n",
        "for fold, (t_idx, v_idx) in enumerate(skf.split(X, y)):\n",
        "    xt, xv = X.iloc[t_idx], X.iloc[v_idx]\n",
        "    yt, yv = y.iloc[t_idx], y.iloc[v_idx]\n",
        "\n",
        "    # Model 1: XGBoost (Fixing the TypeError here)\n",
        "    m1 = xgb.XGBClassifier(\n",
        "        tree_method='hist',\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=7,\n",
        "        early_stopping_rounds=50, # Set in constructor to avoid TypeError\n",
        "        eval_metric='auc',\n",
        "        objective='binary:logistic',\n",
        "        random_state=42 + fold\n",
        "    )\n",
        "    m1.fit(xt, yt, eval_set=[(xv, yv)], verbose=False)\n",
        "\n",
        "    # Model 2: HistGradientBoosting (Native to sklearn, no install needed)\n",
        "    m2 = HistGradientBoostingClassifier(\n",
        "        max_iter=1000,\n",
        "        learning_rate=0.02,\n",
        "        max_depth=8,\n",
        "        l2_regularization=2.0,\n",
        "        early_stopping=True,\n",
        "        random_state=42 + fold\n",
        "    )\n",
        "    m2.fit(xt, yt)\n",
        "\n",
        "    # Predict Probabilities\n",
        "    p1 = m1.predict_proba(X_test)[:, 1]\n",
        "    p2 = m2.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Blend: 50% XGBoost + 50% HistGBM\n",
        "    fold_preds = (p1 + p2) / 2\n",
        "    final_preds += fold_preds / 5\n",
        "\n",
        "    print(f\"‚úÖ Fold {fold+1} complete.\")\n",
        "\n",
        "# --- 5. Final Submission (Guaranteed 300,000 rows) ---\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'diagnosed_diabetes': final_preds\n",
        "})\n",
        "\n",
        "print(f\"Success! Exporting {len(submission)} rows.\")\n",
        "submission.to_csv('submission_blend.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBzKMXCetdu8",
        "outputId": "c2caabf3-20cc-4f77-df44-d1a0e2187418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "üöÄ Running 10-Fold Ultra-Ensemble...\n",
            "Fold 1 ROC AUC: 0.72561\n",
            "Fold 2 ROC AUC: 0.72777\n",
            "Fold 3 ROC AUC: 0.72471\n",
            "Fold 4 ROC AUC: 0.72464\n",
            "Fold 5 ROC AUC: 0.72567\n",
            "Fold 6 ROC AUC: 0.72570\n",
            "Fold 7 ROC AUC: 0.72456\n",
            "Fold 8 ROC AUC: 0.72871\n",
            "Fold 9 ROC AUC: 0.72817\n",
            "Fold 10 ROC AUC: 0.72478\n",
            "\n",
            "üèÜ Estimated Leaderboard Score: 0.72603\n",
            "File 'submission_final_push.csv' created successfully.\n"
          ]
        }
      ],
      "source": [
        "# 1. Environment Setup\n",
        "!pip install --upgrade xgboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# --- 2. Load and Clean ---\n",
        "train = pd.read_csv('train.csv').dropna(subset=['diagnosed_diabetes'])\n",
        "test = pd.read_csv('test.csv')\n",
        "train['diagnosed_diabetes'] = train['diagnosed_diabetes'].astype(int)\n",
        "\n",
        "# --- 3. Clinical Feature Engineering (The Final Boost) ---\n",
        "def final_fe(df):\n",
        "    # TyG Index Proxy: (ln[TG * Glucose/2]) -> since we don't have Glucose,\n",
        "    # we use a metabolic proxy: ln(Triglycerides * BMI)\n",
        "    df['metabolic_index'] = np.log1p(df['triglycerides'] * df['bmi']).astype('float32')\n",
        "\n",
        "    # Heart/Arterial Risk\n",
        "    df['hdl_to_total_ratio'] = (df['hdl_cholesterol'] / (df['cholesterol_total'] + 1e-6)).astype('float32')\n",
        "    df['remnant_chol'] = (df['cholesterol_total'] - df['hdl_cholesterol'] - df['ldl_cholesterol']).astype('float32')\n",
        "\n",
        "    # Blood Pressure Intensity\n",
        "    df['bp_product'] = (df['systolic_bp'] * df['diastolic_bp']).astype('float32')\n",
        "\n",
        "    # Body Composition signal\n",
        "    df['age_waist_interaction'] = (df['age'] * df['waist_to_hip_ratio']).astype('float32')\n",
        "\n",
        "    # Binary Risk Sum\n",
        "    df['comorbidity_count'] = df[['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']].sum(axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "train = final_fe(train)\n",
        "test = final_fe(test)\n",
        "\n",
        "# --- 4. Robust Encoding ---\n",
        "cat_cols = train.select_dtypes(include=['object']).columns\n",
        "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train[cat_cols] = oe.fit_transform(train[cat_cols].astype(str))\n",
        "test[cat_cols] = oe.transform(test[cat_cols].astype(str))\n",
        "\n",
        "X = train.drop(columns=['id', 'diagnosed_diabetes'])\n",
        "y = train['diagnosed_diabetes']\n",
        "X_test = test.drop(columns=['id'])\n",
        "\n",
        "# --- 5. 10-Fold CV & Weighted Ensemble ---\n",
        "# 10 folds is the gold standard for breaking through score plateaus\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "final_test_preds = np.zeros(len(X_test))\n",
        "oof_scores = []\n",
        "\n",
        "print(\"üöÄ Running 10-Fold Ultra-Ensemble...\")\n",
        "\n",
        "for fold, (t_idx, v_idx) in enumerate(skf.split(X, y)):\n",
        "    xt, xv = X.iloc[t_idx], X.iloc[v_idx]\n",
        "    yt, yv = y.iloc[t_idx], y.iloc[v_idx]\n",
        "\n",
        "    # Model 1: XGBoost (Tuned for 0.70)\n",
        "    m1 = xgb.XGBClassifier(\n",
        "        tree_method='hist',\n",
        "        n_estimators=1500,\n",
        "        learning_rate=0.015, # Slower learning for more precision\n",
        "        max_depth=8,\n",
        "        subsample=0.85,\n",
        "        colsample_bytree=0.5,\n",
        "        early_stopping_rounds=100,\n",
        "        eval_metric='auc',\n",
        "        objective='binary:logistic',\n",
        "        random_state=fold\n",
        "    )\n",
        "    m1.fit(xt, yt, eval_set=[(xv, yv)], verbose=False)\n",
        "\n",
        "    # Model 2: HistGBM (Stronger Regularization)\n",
        "    m2 = HistGradientBoostingClassifier(\n",
        "        max_iter=1500,\n",
        "        learning_rate=0.015,\n",
        "        max_depth=10,\n",
        "        l2_regularization=5.0, # High regularization to force generalization\n",
        "        early_stopping=True,\n",
        "        random_state=fold\n",
        "    )\n",
        "    m2.fit(xt, yt)\n",
        "\n",
        "    # Get probabilities\n",
        "    p1 = m1.predict_proba(X_test)[:, 1]\n",
        "    p2 = m2.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # We give 60% weight to XGBoost as it usually has more \"peak\" performance\n",
        "    blend = (p1 * 0.6) + (p2 * 0.4)\n",
        "    final_test_preds += blend / 10\n",
        "\n",
        "    # Track performance\n",
        "    val_p1 = m1.predict_proba(xv)[:, 1]\n",
        "    val_p2 = m2.predict_proba(xv)[:, 1]\n",
        "    fold_auc = roc_auc_score(yv, (val_p1 * 0.6) + (val_p2 * 0.4))\n",
        "    oof_scores.append(fold_auc)\n",
        "    print(f\"Fold {fold+1} ROC AUC: {fold_auc:.5f}\")\n",
        "\n",
        "print(f\"\\nüèÜ Estimated Leaderboard Score: {np.mean(oof_scores):.5f}\")\n",
        "\n",
        "# --- 6. Output Final 300,000 Rows ---\n",
        "submission = pd.DataFrame({'id': test['id'], 'diagnosed_diabetes': final_test_preds})\n",
        "submission.to_csv('submission_final_push.csv', index=False)\n",
        "print(\"File 'submission_final_push.csv' created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-A2F3snQZ0-",
        "outputId": "af0d350f-0e59-488a-a0da-7a3dde51b7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "üöÄ Training on 300124 rows. Predicting on 300000 rows...\n",
            "‚úÖ Fold 1 complete.\n",
            "‚úÖ Fold 2 complete.\n",
            "‚úÖ Fold 3 complete.\n",
            "‚úÖ Fold 4 complete.\n",
            "‚úÖ Fold 5 complete.\n",
            "‚úÖ Fold 6 complete.\n",
            "‚úÖ Fold 7 complete.\n",
            "‚úÖ Fold 8 complete.\n",
            "‚úÖ Fold 9 complete.\n",
            "‚úÖ Fold 10 complete.\n",
            "\n",
            "Final row count: 300000\n",
            "üèÜ Submission saved with exactly 300,000 rows!\n"
          ]
        }
      ],
      "source": [
        "# 1. Install necessary libraries\n",
        "!pip install --upgrade xgboost catboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# --- 2. Load Data ---\n",
        "train = pd.read_csv('train.csv').dropna(subset=['diagnosed_diabetes'])\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# SAFETY LOCK 1: Save the exact 300,000 IDs before any processing\n",
        "original_test_ids = test['id'].values\n",
        "expected_rows = 300000\n",
        "\n",
        "train['diagnosed_diabetes'] = train['diagnosed_diabetes'].astype(int)\n",
        "\n",
        "# --- 3. Feature Engineering ---\n",
        "def ultimate_fe(df):\n",
        "    # Use fillna here to ensure NO rows are dropped from test\n",
        "    df['triglycerides'] = df['triglycerides'].fillna(df['triglycerides'].median())\n",
        "    df['hdl_cholesterol'] = df['hdl_cholesterol'].fillna(df['hdl_cholesterol'].median())\n",
        "    df['bmi'] = df['bmi'].fillna(df['bmi'].median())\n",
        "\n",
        "    df['lipid_index'] = (df['triglycerides'] * df['bmi'] / (df['hdl_cholesterol'] + 1e-6)).astype('float32')\n",
        "    df['atherogenic_index'] = np.log10(df['triglycerides'] / (df['hdl_cholesterol'] + 1e-6)).astype('float32')\n",
        "    df['bmi_waist_age'] = (df['bmi'] * df['waist_to_hip_ratio'].fillna(0) * df['age']).astype('float32')\n",
        "    df['bp_severity'] = (df['systolic_bp'].fillna(0) * df['heart_rate'].fillna(0)).astype('float32')\n",
        "    df['pulse_pressure'] = (df['systolic_bp'].fillna(0) - df['diastolic_bp'].fillna(0)).astype('float32')\n",
        "    return df\n",
        "\n",
        "train = ultimate_fe(train)\n",
        "test = ultimate_fe(test)\n",
        "\n",
        "# --- 4. Encoding ---\n",
        "cat_cols = ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status']\n",
        "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train[cat_cols] = oe.fit_transform(train[cat_cols].astype(str))\n",
        "test[cat_cols] = oe.transform(test[cat_cols].astype(str))\n",
        "\n",
        "X = train.drop(columns=['id', 'diagnosed_diabetes'])\n",
        "y = train['diagnosed_diabetes']\n",
        "X_test = test.drop(columns=['id'])\n",
        "\n",
        "# SAFETY LOCK 2: Pre-allocate a zero-array of exactly 300,000 slots\n",
        "final_test_preds = np.zeros(expected_rows)\n",
        "\n",
        "# --- 5. The Triple-Threat Ensemble ---\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"üöÄ Training on {len(X)} rows. Predicting on {expected_rows} rows...\")\n",
        "\n",
        "for fold, (t_idx, v_idx) in enumerate(skf.split(X, y)):\n",
        "    xt, xv = X.iloc[t_idx], X.iloc[v_idx]\n",
        "    yt, yv = y.iloc[t_idx], y.iloc[v_idx]\n",
        "\n",
        "    # Model 1: XGBoost\n",
        "    m1 = xgb.XGBClassifier(\n",
        "        tree_method='hist', n_estimators=1000, learning_rate=0.02,\n",
        "        max_depth=7, subsample=0.8, colsample_bytree=0.6,\n",
        "        early_stopping_rounds=50, eval_metric='auc', random_state=fold\n",
        "    )\n",
        "    m1.fit(xt, yt, eval_set=[(xv, yv)], verbose=False)\n",
        "\n",
        "    # Model 2: HistGBM\n",
        "    m2 = HistGradientBoostingClassifier(\n",
        "        max_iter=1000, learning_rate=0.02, max_depth=10,\n",
        "        l2_regularization=5.0, early_stopping=True, random_state=fold\n",
        "    )\n",
        "    m2.fit(xt, yt)\n",
        "\n",
        "    # Model 3: CatBoost\n",
        "    m3 = CatBoostClassifier(\n",
        "        iterations=1000, learning_rate=0.03, depth=6,\n",
        "        l2_leaf_reg=3, eval_metric='AUC', random_state=fold,\n",
        "        verbose=False, early_stopping_rounds=50\n",
        "    )\n",
        "    m3.fit(xt, yt, eval_set=(xv, yv))\n",
        "\n",
        "    # Predict on the full X_test (this must return 300k rows)\n",
        "    p1 = m1.predict_proba(X_test)[:, 1]\n",
        "    p2 = m2.predict_proba(X_test)[:, 1]\n",
        "    p3 = m3.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    blend = (p1 * 0.40) + (p2 * 0.30) + (p3 * 0.30)\n",
        "    final_test_preds += blend / 10\n",
        "\n",
        "    print(f\"‚úÖ Fold {fold+1} complete.\")\n",
        "\n",
        "# --- 6. SAFETY LOCK 3: Forced Alignment ---\n",
        "submission = pd.DataFrame({\n",
        "    'id': original_test_ids, # Explicitly use the 300k IDs saved at the start\n",
        "    'diagnosed_diabetes': final_test_preds\n",
        "})\n",
        "\n",
        "# Final row count check\n",
        "print(f\"\\nFinal row count: {len(submission)}\")\n",
        "if len(submission) == expected_rows:\n",
        "    submission.to_csv('submission_ultra_ensemble.csv', index=False)\n",
        "    print(\"üèÜ Submission saved with exactly 300,000 rows!\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: Submission has {len(submission)} rows. Check test data loading.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qT-kHUqrZaB9",
        "outputId": "27babec4-94da-4878-ed1b-bad47558976c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300000"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use this for the final 0.70+ push\n",
        "# It takes the rank of the predictions rather than the raw values\n",
        "\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "# Assume p1, p2, p3 are your probabilities from XGB, HistGBM, and CatBoost\n",
        "# Instead of: blend = (p1 + p2 + p3) / 3\n",
        "# Use Rank Blending:\n",
        "p1_rank = rankdata(p1)\n",
        "p2_rank = rankdata(p2)\n",
        "p3_rank = rankdata(p3)\n",
        "\n",
        "# Normalize the ranks to be between 0 and 1\n",
        "final_blend = (p1_rank + p2_rank + p3_rank) / (3 * len(p1))\n",
        "\n",
        "# This technique is much more robust to AUC optimization\n",
        "len(final_blend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "y9O7DxT8Ca_5",
        "outputId": "7a06c0ce-e3dc-432f-ab0e-2437b08b2e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-916892532.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade xgboost catboost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install --upgrade xgboost catboost\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "train = pd.read_csv('train.csv').dropna(subset=['diagnosed_diabetes'])\n",
        "test = pd.read_csv('test.csv')\n",
        "train['diagnosed_diabetes'] = train['diagnosed_diabetes'].astype(int)\n",
        "\n",
        "# --- 2. Advanced Clinical Feature Engineering ---\n",
        "def expert_fe(df):\n",
        "    # Metabolic Syndrome Score (Proxy)\n",
        "    # High BP + High BMI + High Lipids\n",
        "    df['high_bp'] = ((df['systolic_bp'] > 130) | (df['diastolic_bp'] > 80)).astype(int)\n",
        "    df['high_bmi'] = (df['bmi'] > 30).astype(int)\n",
        "    df['high_tg'] = (df['triglycerides'] > 150).astype(int)\n",
        "    df['metabolic_score'] = df['high_bp'] + df['high_bmi'] + df['high_tg']\n",
        "\n",
        "    # Clinical Ratios\n",
        "    df['tg_hdl_ratio'] = df['triglycerides'] / (df['hdl_cholesterol'] + 1e-6)\n",
        "    df['remnant_chol'] = df['cholesterol_total'] - df['hdl_cholesterol'] - df['ldl_cholesterol']\n",
        "\n",
        "    # Non-Linear Interactions (The 0.70 key)\n",
        "    # The risk of diabetes accelerates as both age and BMI increase together\n",
        "    df['age_bmi_interaction'] = (df['age'] * df['bmi']) / 100\n",
        "    df['bp_age_interaction'] = (df['systolic_bp'] * df['age']) / 100\n",
        "\n",
        "    return df\n",
        "\n",
        "train = expert_fe(train)\n",
        "test = expert_fe(test)\n",
        "\n",
        "# --- 3. Encoding ---\n",
        "cat_cols = train.select_dtypes(include=['object']).columns\n",
        "for col in cat_cols:\n",
        "    train[col] = train[col].astype('category').cat.codes\n",
        "    test[col] = test[col].astype('category').cat.codes\n",
        "\n",
        "X = train.drop(columns=['id', 'diagnosed_diabetes'])\n",
        "y = train['diagnosed_diabetes']\n",
        "X_test = test.drop(columns=['id'])\n",
        "\n",
        "# --- 4. 10-Fold Rank-Based Ensemble ---\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Arrays to store the final RANKS\n",
        "# We use ranks because AUC is all about ordering\n",
        "xgb_preds = np.zeros(len(X_test))\n",
        "cat_preds = np.zeros(len(X_test))\n",
        "hgb_preds = np.zeros(len(X_test))\n",
        "\n",
        "print(\"üöÄ Starting 10-Fold Rank Ensemble...\")\n",
        "\n",
        "for fold, (t_idx, v_idx) in enumerate(skf.split(X, y)):\n",
        "    xt, xv = X.iloc[t_idx], X.iloc[v_idx]\n",
        "    yt, yv = y.iloc[t_idx], y.iloc[v_idx]\n",
        "\n",
        "    # XGBoost\n",
        "    m1 = xgb.XGBClassifier(tree_method='hist', n_estimators=1500, learning_rate=0.01,\n",
        "                           max_depth=8, subsample=0.8, colsample_bytree=0.6,\n",
        "                           early_stopping_rounds=50, eval_metric='auc', random_state=fold)\n",
        "    m1.fit(xt, yt, eval_set=[(xv, yv)], verbose=False)\n",
        "    # Store the RANK of the prediction, not the probability\n",
        "    xgb_preds += rankdata(m1.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    # CatBoost\n",
        "    m2 = CatBoostClassifier(iterations=1500, learning_rate=0.02, depth=7, random_state=fold,\n",
        "                            verbose=False, early_stopping_rounds=50, eval_metric='AUC')\n",
        "    m2.fit(xt, yt, eval_set=(xv, yv))\n",
        "    cat_preds += rankdata(m2.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    # HistGBM\n",
        "    m3 = HistGradientBoostingClassifier(max_iter=1500, learning_rate=0.015, max_depth=10,\n",
        "                                         l2_regularization=5.0, random_state=fold)\n",
        "    m3.fit(xt, yt)\n",
        "    hgb_preds += rankdata(m3.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    print(f\"‚úÖ Fold {fold+1} complete.\")\n",
        "\n",
        "# --- 5. Final Blending & Scaling ---\n",
        "# We average the RANKS, then scale them between 0 and 1\n",
        "# This is much more stable for AUC than averaging raw probabilities\n",
        "final_ranks = (xgb_preds * 0.4 + cat_preds * 0.3 + hgb_preds * 0.3)\n",
        "final_probs = (final_ranks - final_ranks.min()) / (final_ranks.max() - final_ranks.min())\n",
        "\n",
        "# --- 6. The 300,000 Row Check ---\n",
        "submission = pd.DataFrame({'id': test['id'], 'diagnosed_diabetes': final_probs})\n",
        "print(f\"Final Count: {len(submission)}\")\n",
        "submission.to_csv('submission_rank_ensemble.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"],\n",
        "    \"Validation AUC\": [auc_logreg, auc_rf, auc_xgb]\n",
        "})\n",
        "\n",
        "results.sort_values(\"Validation AUC\", ascending=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "T0pGtza-qoKH",
        "outputId": "40f47161-e2ee-4900-ca58-1bb58ffe81bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3732735285.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = pd.DataFrame({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Logistic Regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"XGBoost\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Validation AUC\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mauc_logreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_xgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}